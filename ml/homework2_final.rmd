---
title: "Homework 2"
author: "Charles Hanks"
date: "01/18/2023"
output: 
  html_document:
    df_print: kable
    fig_width: 11
    fig_height: 8
---

**Directions:**

Please turn in **both** a knitted HTML file *and* your Rmd file on WISE.

Good luck!

# Setup (1pt)

Change the author of this RMD file to be yourself and modify the below code so that you can successfully load the 'wine.rds' data file from your own computer.

```{r setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
knitr::opts_knit$set(root.dir = "/Users/charleshanks/Desktop/MSDS/SPRING_23/ML")
library(tidyverse)
library(caret)
library(fastDummies)
wine = read_rds("wine.rds")
```

# Feature Engineering (3pts)

1. Modify the below code and create a total of 10 features (including points). 
2. Make sure that you remove all rows with a missing value. 
3. Make sure that log(price) and your features are the only columns that remain in the wino dataframe.

*Note: each item in a factor variable counts as one feature. I.e., each variety of wine counts as one feature, even though they are all in the same column within the dataframe.*

```{r}
library(caret)

head(wine)

vin = wine %>%
      mutate(lprice = log(price),
             critic = fct_lump(taster_name,3),
             before_y2k = year < 2000,
             winery = fct_lump(winery,4), 
             estate = designation == "Estate") %>%
            select(lprice, points, critic, before_y2k, winery, estate) %>% 
      drop_na(.)


  
      

             
  

```

# Caret (5pts)

1. Use the Caret library to partition the wino dataframe into an 80/20 split. 
2. Then run a linear regression with bootstrap resampling. 
3. Report RMSE when your model is run on the test partition of the data.

*Hint: control <- trainControl(method="boot", number=5)*

```{r}
wino_index = createDataPartition(wino$lprice, p  = .8, list = FALSE) 

wino_train <- wino[ wino_index, ]
wino_test <- wino[-wino_index, ]

control <- trainControl(method="boot", number=5)

modelo <- train(lprice ~ .,
             data = wino_train,
             method = "lm",
             trControl = control)

wino_pred <- predict(modelo, wino_test)

postResample(pred = wino_pred, obs=wino_test$lprice)
```


# Variable selection (1pt)

Graph the importance of your 10 features.

```{r}
importance <- varImp(modelo, scale=TRUE)
# plot importance
plot(importance)
```


## (2pts)

Explain how the bootstrap method in train control you used differs from cross validation (see the link to feat.engineering in the slides).

**Answer:**



# Bonus (3pts)

1. Execute 'set.seed(504)' prior to running your (training/test) data partition
2. Generate an RMSE on the test data of < 0.47 (1pt), < 0.46 (2pts), or < 0.45 (3pts)







